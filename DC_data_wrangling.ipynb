{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import kaggle\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I download using requests / API? <br>\n",
    "https://github.com/Kaggle/kaggle-api <br>\n",
    "kaggle datasets download -d christophercorrea/dc-residential-properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do I not write the entire file path?\n",
    "data = pd.read_csv('/Users/Julia/dc-residential-properties/DC_Properties.csv', low_memory=False)\n",
    "print(data.shape)\n",
    "print(data.columns.tolist())\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddat = pd.DataFrame.drop(data, columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine BR columns\n",
    "ddat['BATHRMS'] = ddat['BATHRM'] + ddat['HF_BATHRM']\n",
    "ddat = pd.DataFrame.drop(ddat, columns = ['BATHRM', 'HF_BATHRM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentages of NaN values per column\n",
    "perc_nan=(ddat.isnull().sum(axis = 0))/len(ddat)\n",
    "#delete NaN rows from columns with few NaN values:\n",
    "dlist = (perc_nan[perc_nan <= 0.02].index).tolist()\n",
    "print(dlist)\n",
    "ddat = ddat.dropna(subset=dlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate rows with more NaN values\n",
    "print(perc_nan[perc_nan > 0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Are values the same for CITY and STATE?\n",
    "print(data.CITY.value_counts())\n",
    "print(data.STATE.value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Drop because unessential and high percentage of missing data:\n",
    "  * CMPLX_NUM\n",
    "Drop because same values for all\n",
    "  * STATE\n",
    "  * CITY\n",
    "Drop because we have latitute/longitude and x/y coords:\n",
    "  * FULLADDRESS\n",
    "  * NATIONALGRID\n",
    "Predict with latitute/longitude\n",
    "  * ASSESSMENT_SUBNBHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddat = pd.DataFrame.drop(ddat, columns=['CMPLX_NUM', 'STATE', 'CITY', 'FULLADDRESS', 'NATIONALGRID'])\n",
    "print(ddat.shape)\n",
    "print(ddat.columns.tolist())\n",
    "ddat.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will make a small dataset, which contains no null values from price. \n",
    "sdat = ddat.dropna(subset=['PRICE'])\n",
    "print(sdat.shape)\n",
    "sdat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we remove all NaNs, we have no data.\n",
    "ldat = sdat.dropna()\n",
    "ldat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types of data in df\n",
    "sdat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TWO LISTS OF COLUMNS. ONE CATEGORICAL, ONE NUMERICAL catcol and numcol\n",
    "#TWO DFS of categorical and numerical. catdf and numdf\n",
    "catcol = []\n",
    "numcol = []\n",
    "for col in sdat.columns:\n",
    "    if (sdat[col].dtype == object):\n",
    "        catcol.append(col)\n",
    "    if (sdat[col].dtype == np.int64) or (sdat[col].dtype == np.float64):\n",
    "        numcol.append(col)\n",
    "catdf = sdat[catcol].astype('category')\n",
    "numdf = sdat[numcol].astype(np.float64)\n",
    "print(catcol)\n",
    "print(numcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show information about values, outlier counts, and fences per numerical variable\n",
    "def show_outliers(df_in, col):\n",
    "    q1 = df_in[col].quantile(0.25)\n",
    "    q3 = df_in[col].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    df_out = df_in.loc[(df_in[col] < fence_low) | (df_in[col] > fence_high)]\n",
    "    print(col)\n",
    "    print(\"fence_low:\", fence_low) \n",
    "    print(\"Q1:\", q1)\n",
    "    print(\"Q3:\", q3) \n",
    "    print(\"fence_high:\", fence_high)\n",
    "    print(\"num_outliers:\", len(df_out))\n",
    "    print((df_in[col].value_counts().sort_index()).head(5))\n",
    "    print((df_in[col].value_counts().sort_index()).tail(5))\n",
    "for col in numdf.columns:\n",
    "    show_outliers(numdf, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_outliers(df_in, col, slow, shigh):\n",
    "    q1 = df_in[col].quantile(0.25)\n",
    "    q3 = df_in[col].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-slow*iqr\n",
    "    fence_high = q3+shigh*iqr\n",
    "    df_out = df_in.loc[(df_in[col] < fence_low) | (df_in[col] > fence_high)]\n",
    "    print(\"Percentage of outliers:\", len(df_out)/len(df_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perc_outliers(sdat, 'LIVING_GBA', 1.5, 1.5))\n",
    "sns.boxplot(x=sdat['LIVING_GBA'], whis=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sdat['LIVING_GBA'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perc_outliers(sdat, 'GBA', 1.5, 1.5))\n",
    "sns.boxplot(x=sdat['GBA'], whis=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sdat['GBA'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perc_outliers(sdat, 'PRICE', 1, 2.5))\n",
    "sns.boxplot(x=sdat['PRICE'], whis=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sdat['PRICE'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perc_outliers(sdat, 'LANDAREA', 1, 2.5))\n",
    "sns.boxplot(x=sdat['LANDAREA'], whis=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(sdat['LANDAREA'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking values for categorical:\n",
    "for col in catdf.columns:\n",
    "    print(col) \n",
    "    print(catdf[col].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING OUTLIERS: When limiting these values, the data shrunk considerably. \n",
    "#The only data that was likely faulty (and not just out of \"the norm\") was\n",
    "#STORIES: 250.00, 275.00, 826.00        \n",
    "#YR_RMDL: 20\n",
    "\n",
    "odat = sdat.loc[(sdat['NUM_UNITS'] >= 1) & (sdat['NUM_UNITS'] <= 4) & (sdat['ROOMS'] <= 12) & (sdat['BEDRM'] <= 6) & (sdat['YR_RMDL'] >= 1880) & \n",
    "          (sdat['STORIES'] >= 1) & (sdat['STORIES'] <= 3) & (sdat['KITCHENS'] >= 1) & (sdat['KITCHENS'] <= 4) & (sdat['FIREPLACES'] >= 1) & \n",
    "          (sdat['FIREPLACES'] <= 3) & (sdat['BATHRMS'] >= 1) & (sdat['BATHRMS'] <= 7)]\n",
    "\n",
    "odat2 = sdat.loc[((sdat['STORIES'] < 30) | (sdat['STORIES'].isna()))  & ((sdat['YR_RMDL'] >= 1880) | (sdat['YR_RMDL'].isna()))]\n",
    "\n",
    "print(sdat.shape)\n",
    "print(odat2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removeing outliers from GBA, LIVING_GBA, LANDAREA, and PRICE\n",
    "\n",
    "takind = []\n",
    "def remove_outliers (df_in, col, slow, shigh):\n",
    "    q1 = df_in[col].quantile(0.25)\n",
    "    q3 = df_in[col].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-slow*iqr\n",
    "    fence_high = q3+shigh*iqr\n",
    "    global iout\n",
    "    iout = (df_in.loc[(df_in[col] < fence_low) | (df_in[col] > fence_high)]).index.tolist()\n",
    "    for i in iout:\n",
    "        if i not in takind:\n",
    "            takind.append(i) \n",
    "    \n",
    "remove_outliers(odat2, 'GBA', 1.5, 1.5)\n",
    "remove_outliers(odat2, 'LIVING_GBA', 1.5, 1.5)\n",
    "remove_outliers(odat2, 'LANDAREA', 1, 2.5)\n",
    "remove_outliers(odat2, 'PRICE', 1, 2.5)\n",
    "print(len(takind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odatd = odat2.drop(index=takind)\n",
    "odatd.shape\n",
    "odatd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAT                  0.000000\n",
      "AC                    0.000000\n",
      "NUM_UNITS             0.422989\n",
      "ROOMS                 0.000000\n",
      "BEDRM                 0.000000\n",
      "AYB                   0.000000\n",
      "YR_RMDL               0.413240\n",
      "EYB                   0.000000\n",
      "STORIES               0.423268\n",
      "SALEDATE              0.000000\n",
      "PRICE                 0.000000\n",
      "QUALIFIED             0.000000\n",
      "SALE_NUM              0.000000\n",
      "GBA                   0.422989\n",
      "BLDG_NUM              0.000000\n",
      "STYLE                 0.422989\n",
      "STRUCT                0.422989\n",
      "GRADE                 0.422989\n",
      "CNDTN                 0.422989\n",
      "EXTWALL               0.422989\n",
      "ROOF                  0.422989\n",
      "INTWALL               0.422989\n",
      "KITCHENS              0.423001\n",
      "FIREPLACES            0.000000\n",
      "USECODE               0.000000\n",
      "LANDAREA              0.000000\n",
      "GIS_LAST_MOD_DTTM     0.000000\n",
      "SOURCE                0.000000\n",
      "LIVING_GBA            0.577011\n",
      "ZIPCODE               0.000000\n",
      "LATITUDE              0.000000\n",
      "LONGITUDE             0.000000\n",
      "ASSESSMENT_NBHD       0.000000\n",
      "ASSESSMENT_SUBNBHD    0.195839\n",
      "CENSUS_TRACT          0.000000\n",
      "CENSUS_BLOCK          0.426124\n",
      "WARD                  0.000000\n",
      "SQUARE                0.000000\n",
      "X                     0.000000\n",
      "Y                     0.000000\n",
      "QUADRANT              0.000000\n",
      "BATHRMS               0.000000\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#percentage of missing data per row in new dataset\n",
    "def missingdat(df):\n",
    "    percnan=(df.isnull().sum(axis=0))/len(df)\n",
    "    nulcolstat = percnan[percnan>0]\n",
    "    nullist = (nulcolstat.index).tolist()\n",
    "    nuldat = sdat[nullist]\n",
    "    print(nulcolstat)\n",
    "print(missingdat(odatd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null from SALEDATE\n",
    "odatd = odatd.dropna(subset=['SALEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create categorical and numerical dataframes\n",
    "catcol = []\n",
    "intcol = []\n",
    "for col in odatd.columns:\n",
    "    if (odatd[col].dtype == object):\n",
    "        catcol.append(col)\n",
    "    if (odatd[col].dtype == np.int64) or (odatd[col].dtype == np.float64):\n",
    "        numcol.append(col)\n",
    "catdf = odatd[catcol].astype('category')\n",
    "numdf = odatd[numcol].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Latitute and Longitude to sort \n",
    "tsortd = odatd.sort_values(['LATITUDE', 'LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill using rolling mean\n",
    "#now, get the new frame to just have the na values filled with the \n",
    "#odatd[col].rolling(11, center=True, min_periods=1).mean()\n",
    "dfill = pd.DataFrame()\n",
    "for col in numdf.columns:\n",
    "    dfill[col] = tsortd[col].fillna(tsortd[col].rolling(301, center=True, min_periods=1).mean())\n",
    "print(missingdat(tsortd))\n",
    "print(missingdat(dfill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>HEAT</th>\n",
       "      <th>AC</th>\n",
       "      <th>SALEDATE</th>\n",
       "      <th>QUALIFIED</th>\n",
       "      <th>STYLE</th>\n",
       "      <th>STRUCT</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>CNDTN</th>\n",
       "      <th>EXTWALL</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>INTWALL</th>\n",
       "      <th>GIS_LAST_MOD_DTTM</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>ASSESSMENT_NBHD</th>\n",
       "      <th>ASSESSMENT_SUBNBHD</th>\n",
       "      <th>CENSUS_BLOCK</th>\n",
       "      <th>WARD</th>\n",
       "      <th>SQUARE</th>\n",
       "      <th>QUADRANT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASSESSMENT_NBHD</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16th Street Heights</th>\n",
       "      <th>0</th>\n",
       "      <td>Hot Water Rad</td>\n",
       "      <td>Y</td>\n",
       "      <td>2016-08-18 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "      <td>2 Story</td>\n",
       "      <td>Single</td>\n",
       "      <td>Good Quality</td>\n",
       "      <td>Good</td>\n",
       "      <td>Common Brick</td>\n",
       "      <td>Metal- Sms</td>\n",
       "      <td>Hardwood</td>\n",
       "      <td>2018-07-22 18:01:43</td>\n",
       "      <td>Residential</td>\n",
       "      <td>16th Street Heights</td>\n",
       "      <td>049 A 16th Street Heights</td>\n",
       "      <td>002001 2010</td>\n",
       "      <td>Ward 4</td>\n",
       "      <td>2798</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American University</th>\n",
       "      <th>0</th>\n",
       "      <td>Warm Cool</td>\n",
       "      <td>Y</td>\n",
       "      <td>2005-09-30 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "      <td>2 Story</td>\n",
       "      <td>Single</td>\n",
       "      <td>Good Quality</td>\n",
       "      <td>Good</td>\n",
       "      <td>Common Brick</td>\n",
       "      <td>Slate</td>\n",
       "      <td>Hardwood</td>\n",
       "      <td>2018-07-22 18:01:43</td>\n",
       "      <td>Residential</td>\n",
       "      <td>American University</td>\n",
       "      <td>001 B American University</td>\n",
       "      <td>001001 1013</td>\n",
       "      <td>Ward 3</td>\n",
       "      <td>1730</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anacostia</th>\n",
       "      <th>0</th>\n",
       "      <td>Forced Air</td>\n",
       "      <td>Y</td>\n",
       "      <td>2013-07-16 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "      <td>2 Story</td>\n",
       "      <td>Row Inside</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>Common Brick</td>\n",
       "      <td>Metal- Sms</td>\n",
       "      <td>Hardwood</td>\n",
       "      <td>2018-07-22 18:01:43</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Anacostia</td>\n",
       "      <td>002 B Anacostia</td>\n",
       "      <td>007504 1004</td>\n",
       "      <td>Ward 8</td>\n",
       "      <td>5807</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry Farms</th>\n",
       "      <th>0</th>\n",
       "      <td>Forced Air</td>\n",
       "      <td>Y</td>\n",
       "      <td>2006-02-08 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "      <td>2 Story</td>\n",
       "      <td>Row Inside</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>Common Brick</td>\n",
       "      <td>Built Up</td>\n",
       "      <td>Hardwood</td>\n",
       "      <td>2018-07-22 18:01:38</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>Barry Farms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>007407 2008</td>\n",
       "      <td>Ward 8</td>\n",
       "      <td>5869</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berkley</th>\n",
       "      <th>0</th>\n",
       "      <td>Warm Cool</td>\n",
       "      <td>Y</td>\n",
       "      <td>2014-06-27 00:00:00</td>\n",
       "      <td>Q</td>\n",
       "      <td>2 Story</td>\n",
       "      <td>Single</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Common Brick</td>\n",
       "      <td>Comp Shingle</td>\n",
       "      <td>Hardwood</td>\n",
       "      <td>2018-07-22 18:01:43</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Berkley</td>\n",
       "      <td>004 A Berkley</td>\n",
       "      <td>000802 1001</td>\n",
       "      <td>Ward 3</td>\n",
       "      <td>1368</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                HEAT AC             SALEDATE QUALIFIED  \\\n",
       "ASSESSMENT_NBHD                                                          \n",
       "16th Street Heights 0  Hot Water Rad  Y  2016-08-18 00:00:00         Q   \n",
       "American University 0      Warm Cool  Y  2005-09-30 00:00:00         Q   \n",
       "Anacostia           0     Forced Air  Y  2013-07-16 00:00:00         Q   \n",
       "Barry Farms         0     Forced Air  Y  2006-02-08 00:00:00         Q   \n",
       "Berkley             0      Warm Cool  Y  2014-06-27 00:00:00         Q   \n",
       "\n",
       "                         STYLE      STRUCT         GRADE    CNDTN  \\\n",
       "ASSESSMENT_NBHD                                                     \n",
       "16th Street Heights 0  2 Story      Single  Good Quality     Good   \n",
       "American University 0  2 Story      Single  Good Quality     Good   \n",
       "Anacostia           0  2 Story  Row Inside       Average  Average   \n",
       "Barry Farms         0  2 Story  Row Inside       Average  Average   \n",
       "Berkley             0  2 Story      Single     Very Good     Good   \n",
       "\n",
       "                            EXTWALL          ROOF   INTWALL  \\\n",
       "ASSESSMENT_NBHD                                               \n",
       "16th Street Heights 0  Common Brick    Metal- Sms  Hardwood   \n",
       "American University 0  Common Brick         Slate  Hardwood   \n",
       "Anacostia           0  Common Brick    Metal- Sms  Hardwood   \n",
       "Barry Farms         0  Common Brick      Built Up  Hardwood   \n",
       "Berkley             0  Common Brick  Comp Shingle  Hardwood   \n",
       "\n",
       "                         GIS_LAST_MOD_DTTM       SOURCE      ASSESSMENT_NBHD  \\\n",
       "ASSESSMENT_NBHD                                                                \n",
       "16th Street Heights 0  2018-07-22 18:01:43  Residential  16th Street Heights   \n",
       "American University 0  2018-07-22 18:01:43  Residential  American University   \n",
       "Anacostia           0  2018-07-22 18:01:43  Residential            Anacostia   \n",
       "Barry Farms         0  2018-07-22 18:01:38  Condominium          Barry Farms   \n",
       "Berkley             0  2018-07-22 18:01:43  Residential              Berkley   \n",
       "\n",
       "                              ASSESSMENT_SUBNBHD CENSUS_BLOCK    WARD SQUARE  \\\n",
       "ASSESSMENT_NBHD                                                                \n",
       "16th Street Heights 0  049 A 16th Street Heights  002001 2010  Ward 4   2798   \n",
       "American University 0  001 B American University  001001 1013  Ward 3   1730   \n",
       "Anacostia           0            002 B Anacostia  007504 1004  Ward 8   5807   \n",
       "Barry Farms         0                        NaN  007407 2008  Ward 8   5869   \n",
       "Berkley             0              004 A Berkley  000802 1001  Ward 3   1368   \n",
       "\n",
       "                      QUADRANT  \n",
       "ASSESSMENT_NBHD                 \n",
       "16th Street Heights 0       NW  \n",
       "American University 0       NW  \n",
       "Anacostia           0       SE  \n",
       "Barry Farms         0       SE  \n",
       "Berkley             0       NW  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df with mode values for groupby\n",
    "modedf = pd.DataFrame()\n",
    "for col in catdf.columns:\n",
    "    modedf[col] = tsortd.groupby('ASSESSMENT_NBHD')[col].apply(lambda x: x.mode())\n",
    "modedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW DO I USE THE MODE VALUES IN THIS TABLE TO FILL THE NA VALUES IN THE DATASET \n",
    "#BY REFERENCING INDEX AND COLUMN?\n",
    "#I thought the solution below would work...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAT                  0.000000\n",
      "AC                    0.000000\n",
      "SALEDATE              0.000000\n",
      "QUALIFIED             0.000000\n",
      "STYLE                 0.422989\n",
      "STRUCT                0.422989\n",
      "GRADE                 0.422989\n",
      "CNDTN                 0.422989\n",
      "EXTWALL               0.422989\n",
      "ROOF                  0.422989\n",
      "INTWALL               0.422989\n",
      "GIS_LAST_MOD_DTTM     0.000000\n",
      "SOURCE                0.000000\n",
      "ASSESSMENT_NBHD       0.000000\n",
      "ASSESSMENT_SUBNBHD    0.195839\n",
      "CENSUS_BLOCK          0.426124\n",
      "WARD                  0.000000\n",
      "SQUARE                0.000000\n",
      "QUADRANT              0.000000\n",
      "dtype: float64\n",
      "None\n",
      "HEAT                  0.000000\n",
      "AC                    0.000000\n",
      "SALEDATE              0.000000\n",
      "QUALIFIED             0.000000\n",
      "STYLE                 0.422989\n",
      "STRUCT                0.422989\n",
      "GRADE                 0.422989\n",
      "CNDTN                 0.422989\n",
      "EXTWALL               0.422989\n",
      "ROOF                  0.422989\n",
      "INTWALL               0.422989\n",
      "GIS_LAST_MOD_DTTM     0.000000\n",
      "SOURCE                0.000000\n",
      "ASSESSMENT_NBHD       0.000000\n",
      "ASSESSMENT_SUBNBHD    0.195839\n",
      "CENSUS_BLOCK          0.426124\n",
      "WARD                  0.000000\n",
      "SQUARE                0.000000\n",
      "QUADRANT              0.000000\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#why didn't this work?!\n",
    "for col in catdf.columns:\n",
    "    dfill[col] = tsortd.groupby(\"ASSESSMENT_NBHD\")[col].transform(lambda x: x.fillna(x.mode()))  \n",
    "print(missingdat(odatd[catcol]))\n",
    "print(missingdat(dfill[catcol]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
