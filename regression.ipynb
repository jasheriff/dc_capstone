{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "# special matplotlib argument for improved plots\n",
    "from matplotlib import rcParams\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.read_csv('/Users/Julia/Documents/bootcamp/DC_capstone/finaldf.csv', low_memory=False)\n",
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFICATIONS\n",
    "\n",
    "#new dataframe with timestamp instead of datetime for SALE_DATE\n",
    "finaldf.SALE_DATE = pd.to_datetime(finaldf.SALE_DATE)\n",
    "\n",
    "times = []\n",
    "for i in finaldf['SALE_DATE']:\n",
    "    times.append(datetime.timestamp(i))\n",
    "finaldf['SALE_DATE'] = times\n",
    "    \n",
    "#dropping LATITUDE and LONGITUDE because these values zig-zag between properties.\n",
    "#dropping CENSUS_TRACT because it's included in CENSUS_BLOCK.\n",
    "dropdf = finaldf.drop(['LATITUDE', 'LONGITUDE', 'CENSUS_TRACT'], axis=1)\n",
    "\n",
    "#remove spaces\n",
    "strips=dropdf['CENSUS_BLOCK'].apply(str).str.replace(\" \", \"\")\n",
    "dropdf['CENSUS_BLOCK'] = strips\n",
    "\n",
    "#change numerical to categorical\n",
    "for col in ['SALE_NUM', 'SQUARE', 'CENSUS_BLOCK', 'USECODE', 'ZIPCODE']:\n",
    "    dropdf[col] = dropdf[col].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING DISTRIBUTIONS\n",
    "\n",
    "# it does not appear that the variables would benefit from transformations.\n",
    "\n",
    "def hist_all(df, target):\n",
    "    #scaling numerical cols\n",
    "    num_list = list(df.loc[:, (df.dtypes == np.float64)].columns)\n",
    "    scaledf = pd.DataFrame()\n",
    "    for col in num_list:\n",
    "        scaledf[col] = (df[col] - np.mean(df[col])) / np.std(df[col])\n",
    "    num_list.remove(target)\n",
    "    \n",
    "    #histograms for numerical facets\n",
    "    fig, axs = plt.subplots(len(scaledf.columns)-3,1, figsize=(10,6*len(scaledf.columns)))\n",
    "    plt.rc('xtick', labelsize='small') \n",
    "    plt.rc('ytick', labelsize='small') \n",
    "    for i, name in enumerate(num_list):\n",
    "        if (str(name) != target):\n",
    "            plt.subplot(len(num_list), 1, i+1)\n",
    "            a = plt.hist(scaledf[name], alpha=.5, bins=20)\n",
    "            a = plt.hist(scaledf[target], alpha=.5, bins=20)\n",
    "            plt.xlabel(name)\n",
    "            plt.ylabel(target)\n",
    "            plt.title(\"Histogram of %s\" % name)  \n",
    "    plt.tight_layout()\n",
    "\n",
    "hist_all(dropdf, 'PRICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION MATRIX\n",
    "\n",
    "num_df = dropdf.loc[:, (dropdf.dtypes == np.float64)]\n",
    "num_df.drop('PRICE', axis=1)\n",
    "num_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEATMAP\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "corr = num_df.corr()\n",
    "hm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.2f',\n",
    "                 linewidths=.05)\n",
    "f.subplots_adjust(top=0.93)\n",
    "t= f.suptitle('Housing Facets Correlation Heatmap', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplots of numerical columns\n",
    "num_list = list(dropdf.loc[:, (dropdf.dtypes == np.float64)].columns)\n",
    "scaledf = pd.DataFrame()\n",
    "for col in dropdf[num_list]:\n",
    "    scaledf[col] = (dropdf[col] - np.mean(dropdf[col])) / np.std(dropdf[col])\n",
    "        \n",
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(scaledf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential variables to drop\n",
    "* kitchen and units .917\n",
    "* bedrooms and room .845\n",
    "* bathrooms and bedrooms .735\n",
    "* bathrooms and rooms .729\n",
    "* yr_origin and yr_ext .687\n",
    "* bathrooms and GBA .577\n",
    "* bedrooms and landarea .570\n",
    "* rooms and landarea .561\n",
    "* units and room .515\n",
    "* kitchens and room .514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CENSUS_BLOCK and SQUARE are the most specific geographical facets. \n",
    "\n",
    "geo_facets = ['QUADRANT', 'WARD', 'NBHD', 'SUBNBHD', 'CENSUS_BLOCK', 'ZIPCODE', 'SQUARE']\n",
    "for facet in geo_facets:\n",
    "    print(\"The number of unique values in %s IS %f\" % (facet, len(finaldf[facet].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCALING FOR REGRESSION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale numerical X variables\n",
    "X_cols = dropdf.drop('PRICE', axis=1)\n",
    "\n",
    "num_list = list(dropdf.loc[:, (dropdf.dtypes == np.float64)].columns)\n",
    "num_list.remove('PRICE')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X_cols.copy()\n",
    "X_scaled[num_list] = scaler.fit_transform(X_cols[num_list])\n",
    "\n",
    "# create dummy variables\n",
    "Xdum = pd.get_dummies(X_scaled, drop_first=True)\n",
    "\n",
    "# dataframe for regression: regdf\n",
    "regdf = Xdum.copy()\n",
    "regdf['PRICE'] = dropdf['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of our frame without dummies is {}\".format(finaldf.shape))\n",
    "print(\"The size of our regression df is {}\".format(regdf.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FULL MODEL REGRESSION AND OUTLIER REMOVAL WITH STATSMODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression function with sklearn using train/test:\n",
    "\n",
    "X = regdf.drop('PRICE', axis=1).values\n",
    "y = regdf['PRICE'].values\n",
    "\n",
    "def linreg(X, y): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "    reg_all=LinearRegression()\n",
    "    reg_all.fit(X_train, y_train)\n",
    "    y_pred = reg_all.predict(X_test)\n",
    "    print(\"Train R^2: {}\".format(reg_all.score(X_train, y_train)))\n",
    "    print(\"Test R^2: {}\".format(reg_all.score(X_test, y_test)))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test Root Mean Squared Error: {}\".format(rmse))\n",
    "    \n",
    "linreg(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression using statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = regdf['PRICE']\n",
    "X = regdf.drop('PRICE', axis=1)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "reg_all = sm.OLS(y, X).fit()\n",
    "reg_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leverage plot\n",
    "\n",
    "import statsmodels.graphics.regressionplots as plots\n",
    "\n",
    "fig = plots.influence_plot(reg_all, alpha=0.01, plot_alpha=0.2, fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals plot \n",
    "\n",
    "plt.hist(reg_all.get_influence().resid_studentized_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers and high leverage points from dataframe:\n",
    "\n",
    "# Pick leverage cutoff for outliers by approximation (.05)\n",
    "high_leverage_points = np.where(reg_all.get_influence().hat_matrix_diag > 0.05)\n",
    "\n",
    "# Based on the histogram of the studentized residuals, remove outside of normal dist 3 SD away from mean....\n",
    "# or approximate (above 3 in this case)\n",
    "high_studentized_resid = np.where(reg_all.get_influence().resid_studentized_external > 3)\n",
    "\n",
    "remove = np.concatenate([high_leverage_points[0], high_studentized_resid[0]])\n",
    "\n",
    "regdf_no_outiers = regdf.drop(remove)\n",
    "print regdf.shape, regdf_no_outiers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION:\n",
    "\n",
    "#### Potential variables to drop (remove one from each set, compare, leave out. Then progress to the next pair): \n",
    "* ##### kitchens, units, bedrooms, room, bathrooms, bedrooms, yr_origin, yr_ext, GBA, landarea,  \n",
    "\n",
    "* kitchen and units .917\n",
    "* bedrooms and room .845\n",
    "* bathrooms and bedrooms .735\n",
    "* bathrooms and rooms .729\n",
    "* yr_origin and yr_ext .687\n",
    "* bathrooms and GBA .577\n",
    "* bedrooms and landarea .570\n",
    "* rooms and landarea .561\n",
    "* units and room .515\n",
    "* kitchens and room .514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regressions, removing variables in order until RMSE is optimized\n",
    "\n",
    "X = regdf_no_outiers.drop('PRICE', axis=1).values\n",
    "y = regdf_no_outiers['PRICE'].values\n",
    "\n",
    "def linreg(X, y, vars_dropped): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "    reg_all=LinearRegression()\n",
    "    reg_all.fit(X_train, y_train)\n",
    "    y_pred = reg_all.predict(X_test)\n",
    "    print(\"Train R^2: {}\".format(reg_all.score(X_train, y_train)))\n",
    "    print(\"Test R^2 for \" vars_dropped \" : {}\".format(reg_all.score(X_test, y_test)))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test Root Mean Squared Error for \" vars_dropped \": {}\".format(rmse))\n",
    "    \n",
    "linreg(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLIER REMOVAL REMOVAL FROM DF WITHOUT COLINEAR FEATURES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression function with sklearn using train/test:\n",
    "\n",
    "# dataframe with best features\n",
    "feat_df = regdf_no_outliers.drop(   , axis=1)\n",
    "X = feat_df.drop('PRICE', axis=1).values\n",
    "y = feat_df['PRICE'].values\n",
    "\n",
    "def linreg(X, y): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "    reg_all=LinearRegression()\n",
    "    reg_all.fit(X_train, y_train)\n",
    "    y_pred = reg_all.predict(X_test)\n",
    "    print(\"Test R^2: {}\".format(reg_all.score(X_test, y_test)))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test Root Mean Squared Error: {}\".format(rmse))\n",
    "    \n",
    "linreg(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression using statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = feat_df['PRICE']\n",
    "X = feat_df.drop('PRICE', axis=1)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "reg_all = sm.OLS(y, X).fit()\n",
    "reg_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leverage plot\n",
    "\n",
    "import statsmodels.graphics.regressionplots as plots\n",
    "\n",
    "fig = plots.influence_plot(reg_all, alpha=0.01, plot_alpha=0.2, fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals plot \n",
    "\n",
    "plt.hist(reg_all.get_influence().resid_studentized_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers and high leverage points from dataframe:\n",
    "\n",
    "# Pick leverage cutoff for outliers by approximation (.05)\n",
    "high_leverage_points = np.where(reg_all.get_influence().hat_matrix_diag > 0.05)\n",
    "\n",
    "# Based on the histogram of the studentized residuals, remove outside of normal dist 3 SD away from mean....\n",
    "# or approximate (above 3 in this case)\n",
    "high_studentized_resid = np.where(reg_all.get_influence().resid_studentized_external > 3)\n",
    "\n",
    "remove = np.concatenate([high_leverage_points[0], high_studentized_resid[0]])\n",
    "\n",
    "feat_no_outliers = feat_df.drop(remove)\n",
    "print feat_df.shape, feat_no_outliers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGULARIZATION WITH SKLEARN FOR FINAL MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression function\n",
    "def ridgereg(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "    space = np.linspace(0, 1, 10)\n",
    "    param_grid = {'alpha': space}\n",
    "    \n",
    "    ridge = Ridge()\n",
    "    gm_cv = GridSearchCV(ridge, param_grid, cv=5)\n",
    "    gm_cv.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gm_cv.predict(X_test)\n",
    "    r2 = gm_cv.score(X_test, y_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Tuned Ridge alpha: {}\".format(gm_cv.best_params_))\n",
    "    print(\"Tuned Ridge R squared: {}\".format(r2))\n",
    "    print(\"Tuned Ridge MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression function\n",
    "def lassoreg(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "    space = np.linspace(0, 1, 10)\n",
    "    param_grid = {'alpha': space}\n",
    "    \n",
    "    lasso = Lasso()\n",
    "    gm_cv = GridSearchCV(lasso, param_grid, cv=5)\n",
    "    gm_cv.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gm_cv.predict(X_test)\n",
    "    r2 = gm_cv.score(X_test, y_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Tuned LASSO Alpha: {}\".format(gm_cv.best_params_))\n",
    "    print(\"Tuned LASSO R squared: {}\".format(r2))\n",
    "    print(\"Tuned LASSO MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ElasticNet function\n",
    "def elasticnet(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n",
    "    space = np.linspace(0, 1, 10)\n",
    "    param_grid = {'l1_ratio': space}\n",
    "    \n",
    "    elastic_net = ElasticNet()\n",
    "    gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "    gm_cv.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gm_cv.predict(X_test)\n",
    "    r2 = gm_cv.score(X_test, y_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "    print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "    print(\"Tuned ElasticNet MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT SPECIFIC METRICS DESCRIBE OVER FITTING?\n",
    "* compare training with test set. if model works significantly better on training set (R^2. MSE?), then it's overfitting. \n",
    "\n",
    "* \"Regularization\" process (correcting over fitting):\n",
    "    * 1. check for outliers\n",
    "    * 2. remove features\n",
    "    * 3. try ridge lasso elasticnet\n",
    "    * 4. go to other methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#gather features\n",
    "features = \"+\".join(df.columns - [\"annual_inc\"])\n",
    "\n",
    "# get y and X dataframes based on this regression:\n",
    "y, X = dmatrices('annual_inc ~' + features, df, return_type='dataframe')\n",
    "\n",
    "# For each X, calculate VIF and save in dataframe\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "\n",
    "vif.round(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
